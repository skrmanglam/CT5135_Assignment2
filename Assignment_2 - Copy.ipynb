{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT5135 Research Topics in AI\n",
    "\n",
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Student ID(s): 22229358, 22230186, 20230220\n",
    "* Student name(s): KOSTADIN GEORGIEV, YAMINI GIRKAR, SHUBHAM MANGLAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, activations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided images are of different heights so they should be resized to the same resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a function which applies callback to each .jpg image in a directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_directory(dir, callback, label=None):\n",
    "    for dirname, _, filenames in os.walk(dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                id = filename[:-4]\n",
    "                pathname = os.path.join(dirname, filename)\n",
    "                im = Image.open(pathname)\n",
    "                imnp = np.array(im, dtype=float)\n",
    "\n",
    "                if len(imnp.shape) != 3:\n",
    "                    print(\"This is 1 channel, so we omit it\",\n",
    "                          imnp.shape, filename)\n",
    "                    continue\n",
    "\n",
    "                callback(id, imnp, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the dimensions of each image in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 1 channel, so we omit it (683, 1024) 4b9ef3ce2685ee32.jpg\n",
      "This is 1 channel, so we omit it (914, 1024) 5a71db307230880e.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>channels</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01ad3ff1d94eb557</th>\n",
       "      <td>670</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0346463867a297f4</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>038fae9e70c4c3f1</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>053608552d63f724</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>053dab62fbb47736</th>\n",
       "      <td>682</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb4d2e0c0252fdc2</th>\n",
       "      <td>682</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb4f5968c7866a3e</th>\n",
       "      <td>699</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4495f8511553631</th>\n",
       "      <td>680</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8d3c3d8be68c4fd</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8e3dd41b584f645</th>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>3</td>\n",
       "      <td>not_alpaca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  height  width  channels       label\n",
       "01ad3ff1d94eb557     670   1024         3      alpaca\n",
       "0346463867a297f4     768   1024         3      alpaca\n",
       "038fae9e70c4c3f1     768   1024         3      alpaca\n",
       "053608552d63f724     768   1024         3      alpaca\n",
       "053dab62fbb47736     682   1024         3      alpaca\n",
       "...                  ...    ...       ...         ...\n",
       "eb4d2e0c0252fdc2     682   1024         3  not_alpaca\n",
       "eb4f5968c7866a3e     699   1024         3  not_alpaca\n",
       "f4495f8511553631     680   1024         3  not_alpaca\n",
       "f8d3c3d8be68c4fd     768   1024         3  not_alpaca\n",
       "f8e3dd41b584f645     768   1024         3  not_alpaca\n",
       "\n",
       "[325 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['height', 'width', 'channels', 'label'])\n",
    "\n",
    "def get_img_shape(id, imnp, label):\n",
    "    height, width, channel = imnp.shape\n",
    "    df.loc[id] = [height, width, channel, label]\n",
    "\n",
    "walk_directory('dataset/alpaca', get_img_shape, 'alpaca')\n",
    "walk_directory('dataset/not_alpaca', get_img_shape, 'not_alpaca')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images will be resized to 28 x 28\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = df['height'].min()\n",
    "IMG_WIDTH = df['width'].min()\n",
    "\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "\n",
    "print('Images will be resized to', IMG_HEIGHT, 'x', IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(label):\n",
    "    source_dir = 'dataset/' + label\n",
    "    target_dir = 'dataset_resized/'+ label\n",
    "    subset = df.loc[df['label'] == label]\n",
    "\n",
    "    for id, image in subset.iterrows():\n",
    "        id = str(id)\n",
    "        filename = id + \".jpg\"\n",
    "        \n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        target_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        image = Image.open(source_path)\n",
    "        image = image.resize((IMG_WIDTH, IMG_HEIGHT), Image.NEAREST)\n",
    "        image.save(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_images('alpaca')\n",
    "resize_images('not_alpaca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(dir):\n",
    "    img_array = []\n",
    "    \n",
    "    walk_directory(dir, lambda id, imnp, label: img_array.append(imnp))\n",
    "\n",
    "    return np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_alpaca = load_images('dataset_resized/alpaca')\n",
    "img_not_alpaca = load_images('dataset_resized/not_alpaca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpaca: (142, 28, 28, 3)\n",
      "not_alpaca: (183, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "print('alpaca:', img_alpaca.shape)\n",
    "print('not_alpaca:', img_not_alpaca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.imshow(img_alpaca[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create arrays for all images and for all labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_array: (325, 28, 28, 3)\n",
      "labels: (325,)\n"
     ]
    }
   ],
   "source": [
    "lbl_alpaca = np.ones(img_alpaca.shape[0], dtype=int)\n",
    "lbl_not_alpaca = np.zeros(img_not_alpaca.shape[0], dtype=int)\n",
    "labels = np.concatenate((lbl_alpaca, lbl_not_alpaca), axis=0)\n",
    "img_array = np.concatenate((img_alpaca, img_not_alpaca), axis=0)\n",
    "print('img_array:', img_array.shape)\n",
    "print('labels:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale down data from 0-255 to 0-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_scaled = img_array / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one-hot encodings for the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_one_hot_encode = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train/Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 80% of the dataset as training data and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train, y_test) = train_test_split(img_array_scaled, labels_one_hot_encode,\n",
    "                                     train_size = 0.8, random_state = 22229358)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Proposed Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagram of the proposed convolution operation\n",
    "\n",
    "H = height of input image\n",
    "\n",
    "W = width of input image\n",
    "\n",
    "C = number of channels of input\n",
    "\n",
    "![Proposed Layer](img/proposed_layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProposedLayer(layers.Layer):\n",
    "    def __init__(self, filters, rf=(3, 3), activation=None, **kwargs):\n",
    "        super(ProposedLayer, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.rf = rf\n",
    "        self.activation = activations.get(activation)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        batch_size, height, width, channels = input_shape\n",
    "        w_shape = tf.TensorShape((height, width, channels, self.filters))\n",
    "        b_shape = tf.TensorShape((self.filters,))\n",
    "        \n",
    "        batch_size = 1 if batch_size is None else batch_size\n",
    "        z_height = height - self.rf[0] + 1\n",
    "        z_width = width - self.rf[1] + 1\n",
    "#         self.z_shape = (batch_size, z_height, z_width, self.filters)\n",
    "#         self.z = tf.Variable(tf.zeros(self.z_shape, tf.float32), trainable=False)\n",
    "\n",
    "        self.W = self.add_weight(name='kernel', shape=w_shape,\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True, dtype=tf.float32)\n",
    "        self.B = self.add_weight(name='bias', shape=b_shape,\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True, dtype=tf.float32)\n",
    "        \n",
    "        super(ProposedLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        batch_size, height, width, _ = X.shape\n",
    "        batch_size = 1 if batch_size is None else batch_size\n",
    "        z_height = height - self.rf[0] + 1\n",
    "        z_width = width - self.rf[1] + 1\n",
    "        z_shape = (batch_size, z_height, z_width, self.filters)\n",
    "        output_list = []\n",
    "#         z = tf.zeros(z_shape, dtype=np.float32)\n",
    "#         z = tf.Variable(lambda: tf.zeros(z_shape, tf.float32), trainable=False)\n",
    "\n",
    "        for sample in range(batch_size):\n",
    "            k_list = []\n",
    "            for k in range(self.filters):\n",
    "                x = X[sample]\n",
    "                w = self.W[:, :, :, k]\n",
    "                b = self.B[k]\n",
    "                conv = tf.multiply(x, w) + b\n",
    "                i_list = []\n",
    "                for i in range(z_height):\n",
    "                    j_list = []\n",
    "                    for j in range(z_width):\n",
    "                        rf = conv[i:i+self.rf[0], j:j+self.rf[1], :]\n",
    "                        conv_sum = tf.math.reduce_sum(rf)\n",
    "                        j_list.append(conv_sum)\n",
    "                    i_list.append(j_list)\n",
    "                k_list.append(i_list)\n",
    "            output_list.append(k_list)\n",
    "        z = tf.stack(output_list)\n",
    "#         print(z.shape)\n",
    "#         raise\n",
    "#         z = tf.convert_to_tensor(z, tf.float32, name='output')\n",
    "        \n",
    "        return self.activation(z)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple(input_shape[0],\n",
    "                     input_shape[1] - self.rf[0] + 1,\n",
    "                     input_shape[2] - self.rf[1] + 1,\n",
    "                     self.filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_mock = np.ones((1, 28, 28, 3))\n",
    "#l = ProposedLayer(16, (3, 3), activation='relu')\n",
    "#l.build((1, 28, 28, 3))\n",
    "#l.call(l_mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model using proposed layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.p1 = ProposedLayer(16, (3, 3), activation='relu')\n",
    "        self.m1 = layers.MaxPooling2D((2, 2))\n",
    "#         self.p2 = ProposedLayer(12, (3, 3), activation='relu')\n",
    "#         self.m2 = layers.MaxPooling2D((2, 2))\n",
    "#         self.p3 = ProposedLayer(8, (3, 3), activation='relu')\n",
    "#         self.m3 = \n",
    "        self.flat = layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "#         self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.p1(inputs)\n",
    "        x = self.m1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "# n_classes = 2\n",
    "\n",
    "# # Input\n",
    "# inputs = layers.Input(input_shape, batch_size=1)\n",
    "\n",
    "# # Block 1\n",
    "# x0 = ProposedLayer(16, (3, 3), activation='relu')(inputs)\n",
    "# x1 = layers.MaxPooling2D((2, 2))(x0)\n",
    "# # Block 2\n",
    "# x2 = ProposedLayer(12, (3, 3), activation='relu')(x1)\n",
    "# x3 = layers.MaxPooling2D((2, 2))(x2)\n",
    "# # Block 3\n",
    "# x4 = ProposedLayer(8, (3, 3), activation='relu')(x3)\n",
    "# x5 = layers.MaxPooling2D((2, 2))(x4)\n",
    "\n",
    "# # Flatten feature map - embedding size will become 32944\n",
    "# x6 = layers.Flatten()(x5)\n",
    "\n",
    "# # Dense layer for classification\n",
    "# # Start with units in dense layer = power of 2 that is\n",
    "# # closest to (embedding_size / 64)\n",
    "# x7 = layers.Dense(512, activation='relu')(x6)\n",
    "# # Output\n",
    "# outputs = layers.Dense(n_classes, activation='softmax')(x7)\n",
    "\n",
    "# proposed_model = keras.Model(inputs, outputs)\n",
    "# proposed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "                       loss=tf.keras.losses.CategoricalCrossentropy(),  run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/104 [..............................] - ETA: 37:11 - loss: 0.7087"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m proposed_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py:1160\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;124;03m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py:1146\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1315\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1311\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1314\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2891\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2891\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3692\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3691\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py:1135\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1135\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1136\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\engine\\training.py:997\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtape\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:634\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    632\u001b[0m var_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(var_list)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_valid_dtypes(\n\u001b[0;32m    639\u001b[0m     [\n\u001b[0;32m    640\u001b[0m         v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m     ]\n\u001b[0;32m    644\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:510\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;124;03m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:166\u001b[0m, in \u001b[0;36m_SumGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    164\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m input_0_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    168\u001b[0m   \u001b[38;5;66;03m# The shape and reduction indices are statically known, so we use a\u001b[39;00m\n\u001b[0;32m    169\u001b[0m   \u001b[38;5;66;03m# graph-level cache to avoid recomputing `reduced_shape()` for each\u001b[39;00m\n\u001b[0;32m    170\u001b[0m   \u001b[38;5;66;03m# invocation.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m   graph \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:11728\u001b[0m, in \u001b[0;36mtile\u001b[1;34m(input, multiples, name)\u001b[0m\n\u001b[0;32m  11726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m  11727\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 11728\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11729\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m  11731\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proposed_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 2,\n",
    "    epochs = 10,\n",
    "    validation_split = 0.2,\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_train_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m epoch_accuracy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Training loop - using batches of 32\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mds_train_batch\u001b[49m:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m grad(model, x, y)\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds_train_batch' is not defined"
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model parameters\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    # Training loop - using batches of 32\n",
    "    for x, y in ds_train_batch:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "        # End epoch\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                    epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
